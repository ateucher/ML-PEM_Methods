
# function to determine balancing parameters for recipe preparation. 
# Currently set for smote and or downsample combination. 
# Used to determine optimum balancing requirement for dataset. 
balance_optimisation2 <- function(trDat , extrarun = FALSE, extradat = NULL, downsample = TRUE, smote = TRUE){
  
    for(d in ds_iterations){
    #d = ds_iterations[1]
    print(d)
    
    for(i in smote_iterations){
      #i = smote_iterations[1]
      print(i)
      
      # test if enough data in the slice to use smoting 
      
      # set up the parameters for balancing
      downsample_ratio = d  # (0 - 100, Null = 1)
      smote_ratio = i    # 0 - 1, 1 = complete smote
      
      balance_name = paste0("ds_",downsample_ratio,"_sm_", smote_ratio)
      
      
      # Cross validation loop based on slices 
      slices <- unique(trDat$slice) %>% droplevels()
      
      # if(length(slices)<2){
      #   
      #   # switching to transect iteration instead of slices
      #   
      #   trDat_key <- trDat %>%
      #     dplyr::select(c(tid)) %>%
      #     distinct() %>%
      #     mutate(slice = as.factor(seq(1,length(tid),1)))
      #   
      #   trDat <- trDat %>%
      #     dplyr::select(-slice) %>%
      #     left_join(trDat_key)
      #   
      #   slices <- unique(trDat$slice) %>% droplevels()
      #   
      # }
      
      
      # for all slices
      sresults <- foreach(k = levels(slices)) %do% {
        
      #k = levels(slices)[6]
        ### split into train and test based on 5-site slices
        print(k)
        
        # training set
        BGC_train <- trDat %>% dplyr::filter(!slice %in% k) %>%
          filter(is.na(target2) | target2 == "") %>% dplyr::select(-slice) # train only on pure calls
        bgc.label = unique(BGC_train$bgc_cat)        
        # merge in extra point data 
 
               # if(extra = FALSE) {remove(extra)}
        # merge in extra point data
        if(isTRUE(extrarun)) {
          print("adding extra points at each model build")
          BGC_train <- rbind(BGC_train, extradat)
        }
        # check if enough data for each class to smote
        
        MU_count <- BGC_train %>% dplyr::count(target) %>% filter(n < 10) %>%
          pull(target) %>% droplevels()
        
        if(length(MU_count) > 0) {
          print("remove classes with very low training points from smoting test")
          BGC_train <- BGC_train %>% 
            filter(!target %in% MU_count) %>% droplevels()
        }
        # 

        BGC_train <- BGC_train %>%
          dplyr::select(-target2, -transect_id, -tid, -bgc_cat) %>%  drop_na() %>% mutate(target = factor(target)) %>%  droplevels()
        
        
        
        # test set
        BGC_test <- trDat %>% filter(slice %in% k) %>%
          filter(!target %in% MU_count)
        BGC_test_all <- BGC_test # keep for the target2 alt call. 
        BGC_test_transect_no <- length(unique(BGC_test_all$transect_id))
        BGC_test <- BGC_test %>%
          dplyr::select(-slice,-target2,-transect_id, -tid, -bgc_cat)
        # 
        ############### Define test recipes and workflow ###################
        
        # null_recipe <- balance_optimum(indata = BGC_train, 
        #                                downsample = downsample,
        #                                downsample_ratio = downsample_ratio,
        #                                smote= smote, 
        #                                smote_ratio = smote_ratio,
        #                                update_role(tid, new_role = "id variable"))
        
        
        null_recipe <-  recipe(target ~ ., data = BGC_train) %>%
          #update_role(tid, new_role = "id variable") %>%
          step_downsample(target, under_ratio = downsample_ratio) %>%
          step_smote(target, over_ratio = smote_ratio , neighbors = 2, skip = TRUE)
        
        
        randf_spec <- rand_forest(mtry = 10, min_n = 2, trees = 200) %>% 
          set_mode("classification") %>%
          set_engine("ranger", importance = "permutation", verbose = FALSE) 
        
        pem_workflow <- workflow() %>%
          add_recipe(null_recipe) %>%
          add_model(randf_spec)
        
        #######################################################
        PEM_rf1 <- fit(pem_workflow, BGC_train)
        
        #final_fit <- pull_workflow_fit(PEM_rf1) # %>%pull(.predictions)
        final_fit <- extract_fit_parsnip(PEM_rf1)
        
        oob  <- round(PEM_rf1$fit$fit$fit$prediction.error, 3)
        
        ######### Predict Test
        #test_target <- as.data.frame(BGC_test$target) %>% rename(target = 1)
        test_target <- BGC_test_all %>% dplyr::select(target, target2)
        
        test.pred <-  predict(PEM_rf1, BGC_test)
        test.pred <- cbind(test_target, test.pred) %>% 
          mutate_if(is.character, as.factor)
        # levels(train.pred$target)
       
        ###______________________ 
        ## for a test convert all predicted non-for groups into a single nonfor unit for accuracy assessment
        
        test.pred <- test.pred %>%  mutate_if(is.factor, as.character)# %>% 
        # mutate(across(c(target, target2, .pred_class),dplyr::recode("X" %in% "nonfor", "A" = "nonfor", "W_t" = "nonfor", 
        #                                                         "W" = "nonfor", "Sc" = "nonfor", "R" = "nonfor", "F" = "nonfor", 
        #                                                         "Non_veg" = "nonfor","Wat" = "nonfor", "Wb" = "nonfor")))
        # 
        convert <- c("X", "A", "W_t", "W", "Sc", "R", "F", "Non_veg","Wat", "Wb")
        
        test.pred <- test.pred %>% mutate(target = ifelse(target %in% convert, "nonfor", target),
                                          target2 = ifelse(target2 %in% convert, "nonfor", target2) ,
                                          .pred_class = ifelse(.pred_class  %in% convert, "nonfor", .pred_class )) 
        
        test.pred <- test.pred %>%  mutate_if(is.character, as.factor)
      ###_______________________________________________________
       
       ###harmonize factor levels
        targ.lev <- levels(test.pred$target)
        pred.lev <- levels(test.pred$.pred_class)
        levs <- c(targ.lev, pred.lev) %>% unique()
        test.pred$target <- factor(test.pred$target, levels = levs)
        test.pred$.pred_class <- factor(test.pred$.pred_class, levels = levs)
        # output test predictions
        
        test.pred.out <- test.pred %>% mutate(slice = k)
        acc.compare <- acc_metrix(test.pred) %>%
          mutate(slice = k,
                 transect_no = BGC_test_transect_no,
                 acc_type = "test_estimate", 
                 oob = oob, 
                 balance = balance_name,
                 bgc = bgc.label)
        ##use function to add in theta  
        acc.theta <- theta_accuracy(acc.compare, theta = 0.5)
        acc.compare <- cbind(acc.compare,acc.theta)
        
        return(list(acc.compare))
      }
      
      # extract results from sresults
      acc_results <- lapply(sresults, function(x) x[[1]])
      acc <- as.data.frame(rbindlist(acc_results))
      
      write.csv(acc, file = paste(outDir, paste0("acc_", balance_name,".csv"),sep = "/"))
      
      
    } # end of smote iteration
    
  } # end of downsample iteration 
  
}


balance_optimisation_raw <- function(trDat , extrarun = FALSE, extradat = NULL, downsample = FALSE, smote = FALSE){
  
  
      balance_name = "raw"
      
      
      # Cross validation loop based on slices 
      slices <- unique(trDat$slice) %>% droplevels()
      
      # for all slices
      sresults <- foreach(k = levels(slices)) %do% {
        
        #k = levels(slices)[1]
        ### split into train and test based on 5-site slices
        print(k)
        
        # training set
        BGC_train <- trDat %>% dplyr::filter(!slice %in% k) %>%
          filter(is.na(target2) | target2 == "") %>% dplyr::select(-slice)# train only on pure calls
        bgc.label = unique(BGC_train$bgc_cat)  

        # if(extra = FALSE) {remove(extra)}
                    # merge in extra point data
        if(isTRUE(extrarun)) {
          print("adding extra points at each model build")
          BGC_train <- rbind(BGC_train, extradat)
        }

        # check if enough data for each class to smote
        
        MU_count <- BGC_train %>% dplyr::count(target) %>% filter(n < 10) %>%
          pull(target)
        
        if(length(MU_count) != 0) {
          print("remove classes with very low training points from smoting test")
          BGC_train <- BGC_train %>% 
            filter(!target %in% MU_count)
        }
        # 

        BGC_train <- BGC_train %>%
          dplyr::select(-target2, -transect_id) %>%  drop_na() %>% droplevels()# %>% mutate(tid = factor(tid)) %>%  droplevels()
        
        
        
        # test set
        BGC_test <- trDat %>% filter(slice %in% k) %>%
          filter(!target %in% MU_count)
        BGC_test_all <- BGC_test # keep for the target2 alt call. 
        BGC_test_transect_no <- length(unique(BGC_test_all$transect_id))
        BGC_test <- BGC_test %>%
          dplyr::select(-slice,-target2,-transect_id)
        # 
        ############### Define test recipes and workflow ###################
        
        # null_recipe <- balance_optimum(indata = BGC_train, 
        #                                downsample = downsample,
        #                                downsample_ratio = downsample_ratio,
        #                                smote= smote, 
        #                                smote_ratio = smote_ratio,
        #                                update_role(tid, new_role = "id variable"))
        
        
        null_recipe <-  recipe(target ~ ., data = BGC_train) %>%
          update_role(tid, new_role = "id variable")# %>%
          #step_downsample(target, under_ratio = downsample_ratio) %>%
          #step_smote(target, over_ratio = smote_ratio , neighbors = 2)
        
        
        randf_spec <- rand_forest(mtry = 10, min_n = 2, trees = 200) %>% 
          set_mode("classification") %>%
          set_engine("ranger", importance = "permutation", verbose = FALSE) 
        
        pem_workflow <- workflow() %>%
          add_recipe(null_recipe) %>%
          add_model(randf_spec)
        
        #######################################################
        PEM_rf1 <- fit(pem_workflow, BGC_train)
        
        #final_fit <- pull_workflow_fit(PEM_rf1) # %>%pull(.predictions)
        final_fit <- extract_fit_parsnip(PEM_rf1)
        
        oob  <- round(PEM_rf1$fit$fit$fit$prediction.error, 3)
        
        ######### Predict Test
        #test_target <- as.data.frame(BGC_test$target) %>% rename(target = 1)
        test_target <- BGC_test_all %>% dplyr::select(target, target2)
        
        test.pred <-  predict(PEM_rf1, BGC_test)
        test.pred <- cbind(test_target, test.pred) %>% 
          mutate_if(is.character, as.factor)
        # levels(train.pred$target)
        
        ###______________________ 
        ## for a test convert all predicted non-for groups into a single nonfor unit for accuracy assessment
        
        test.pred <- test.pred %>%  mutate_if(is.factor, as.character)# %>% 
          # mutate(across(c(target, target2, .pred_class),dplyr::recode("X" %in% "nonfor", "A" = "nonfor", "W_t" = "nonfor", 
          #                                                         "W" = "nonfor", "Sc" = "nonfor", "R" = "nonfor", "F" = "nonfor", 
          #                                                         "Non_veg" = "nonfor","Wat" = "nonfor", "Wb" = "nonfor")))
          # 
        convert <- c("X", "A", "W_t", "W", "Sc", "R", "F", "Non_veg","Wat", "Wb")

        test.pred <- test.pred %>% mutate(target = ifelse(target %in% convert, "nonfor", target),
                                          target2 = ifelse(target2 %in% convert, "nonfor", target2) ,
                                          .pred_class = ifelse(.pred_class  %in% convert, "nonfor", .pred_class )) 
        
        test.pred <- test.pred %>%  mutate_if(is.character, as.factor)
        ###harmonize levels
        targ.lev <- levels(test.pred$target)
        pred.lev <- levels(test.pred$.pred_class)
        levs <- c(targ.lev, pred.lev) %>% unique()
        test.pred$target <- factor(test.pred$target, levels = levs)
        test.pred$.pred_class <- factor(test.pred$.pred_class, levels = levs)
        # output test predictions
        
        test.pred.out <- test.pred %>% mutate(slice = k)
        acc.compare <- acc_metrix(test.pred) %>%
          mutate(slice = k,
                 transect_no = BGC_test_transect_no,
                 acc_type = "test_estimate", 
                 oob = oob, 
                 balance = balance_name,
                 bgc = bgc.label)
      ##use function to add in theta  
        acc.theta <- theta_accuracy(acc.compare, theta = 0.5)
        acc.compare <- cbind(acc.compare,acc.theta)
        return(list(acc.compare))
      }
      
      # extract results from sresults
      acc_results <- lapply(sresults, function(x) x[[1]])
      acc <- as.data.frame(rbindlist(acc_results))
      
      write.csv(acc, file = paste(outDir, paste0("acc_", balance_name,".csv"),sep = "/"))
      
      
    } # end of smote iteration
    

