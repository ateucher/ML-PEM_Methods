---
title: "Import of Stage 1 Field Transect data for Boundary from Avenza PDF maps schema and consolidate"
subtitle: "by Gen Perkins"
date: "10/06/2020"
output: html_document
---

```{r global_options, include=FALSE }
require(knitr)

```


```{r setup, include=FALSE}

library(tidyverse)
library(sf)
library(stringr)
library(lwgeom)
library(foreach)
library(scales)

```

## Introduction

This script contains functionality for the import data collected by Avenza following field collection of triangular paired transects for Stage 1 data collection.

1. Import transects from shapefiles or geopackage exported from Avenza PDF maps. 

2. Converts data to vector triangles (using point to point at 2.5m resolution). Specifically this converts the points to lines (or track log to lines), add the field sample data as attributes to the line. 

To run this script you will need:  
- field data + tracks collected as .shp or .gpkg files. 
- Mapunit_Legend (csv file which will convert the codes to standard codes)
- 

## 1. Set up folder structure for Stage 1 sampling 

```{r set up folder structure }

AOI <- "KootInvCran"

res <- 5
#res <- 2.5

AOI_dir <- file.path(".", paste0(AOI,"_AOI"))
cov_dir <- file.path(AOI_dir, "1_map_inputs", "covariates")

trans_layout <- file.path(AOI_dir, "2_sample_design", "stage1_StudyDesign", "transect_layout")
trans_data <- file.path(AOI_dir, "2_sample_design", "stage1_StudyDesign", "transect_data") 

output_pnts_dir <- file.path(AOI_dir, "2_sample_design", "stage1_StudyDesign", "training_pts")

map.key  <- read.csv(file.path(AOI_dir, "_MapUnitLegend", 
                                 paste0(AOI, "_MapUnitLegend.csv")), 
                       stringsAsFactor = FALSE)

if(!dir.exists(output_pnts_dir)) dir.create(output_pnts_dir, recursive = TRUE)

```

Setup functions 

1. extend_lines function will extend lines in order for one line to fully intersect another line. This is only used when the track log is selected for sampling. It is contained within the "process_track".

2. process_track function will separate the tracklog based on the given point data. Some refinement required (see [issue](https://github.com/bcgov-c/BEC_DevExchange_Work/issues/21).


```{r Functions}

source(here::here('_functions', 'extend_lines.R'))
source(here::here('_functions', 'make_lines.R'))
source(here::here('_functions', 'transect_sample.R'))
source(here::here('_functions', 'multiline_to_line.R'))
source(here::here('_functions', '_standardise_avenza_input_field_names.R'))

```


## 1) Import and clean Avenza field transect data

1. Import transects from shape files or geopackages exported from Avenza PDF maps. The shape files contain all data collected under the schema and so generally contain all transects collected to date on a single tablet. Need to separate using the original study design transect triangles.


```{r import base files to run analysis, tidy = TRUE, warning=FALSE}

trans <- list.files(trans_layout, pattern = ".gpkg$", full.names = TRUE, recursive = FALSE)

transect_layout <- foreach(x = trans, .combine = rbind) %do% {
  clhs_layers <- st_layers(x)
  lines <- which(clhs_layers[["geomtype"]] %in% c("Line String", "Multi Line String"))
  if(length(lines)) {
    transects <- foreach(y = clhs_layers$name[lines], .combine = rbind) %do% {
      transect <- st_read(x, y, quiet = TRUE) %>% 
        rename_all(recode, geom = "geometry") %>% 
        rename_all(.funs = tolower) %>%
        dplyr::select(id) %>% 
        mutate(id = as.character(id)) %>% 
        st_transform(3005)
    }
  } 
} #%>% dplyr::rename(ID = id)

transect_layout <- unique(transect_layout)

transect_layout_buf <- st_buffer(transect_layout, 10)

st_write(transect_layout, file.path(output_pnts_dir, "transect_layout_s1.gpkg"), delete_layer = TRUE)

#transect_layout <- st_read(file.path(output_pnts_dir, "transect_layout_s1.gpkg"))
#transect_layout_buf <- st_buffer(transect_layout, 10)

```


2. Connect the placemarks waypoints into a traverse using the running number name assigned by PDF maps

The following chunk creates some basic folders and loads in data that will be used across all sampling types (a raster template and the original CLHS transects).


```{r }
# Where data is supplied in differing formats you might need to first split these out into seperate files. 

indat <- "day5"
datafolder <- file.path(trans_data, "raw", "contractors")

# set up post process folder
infolder <- file.path(datafolder, indat) 
singlefolder <- file.path(infolder, "processed")
if(!dir.exists(singlefolder)) dir.create(singlefolder, recursive = TRUE)

# find the point file  
points <- list.files(file.path(infolder), pattern = ".gpkg", full.names = TRUE)

process <- split_gpkgs(infile =points[2], outfolder = singlefolder) 


```


# Once the data is split into seperate files and reviewed then some pre-processing or check before moving to common folder. 

```{r - testing script to check for issues before processing}

indat <- "day10"
datafolder <- file.path(trans_data, "raw", "contractors")
infolder <- file.path(datafolder, indat) 

# find the point file  
points <- list.files(file.path(infolder), pattern = ".gpkg$|.shp$", full.names = TRUE)

#points <- points[1:4]
  
all_points <- foreach(x = points, .combine = rbind) %do% {
  #x = points[5]
  if(length(pts)>0) { 
    
    print(x)
    
    points_read <- st_read(x, quiet = TRUE) %>%
     #names(points_read)
     st_transform(3005) %>% 
     st_zm() %>% 
     rename_all(.funs = tolower)

  } 
  
}

d1 <- all_points
d5 <- all_points
d10 <- all_points
d15 <- all_points

```




Once all files are checked they can be run through the common coding 

```{r prepare raw data (unzip data and split into points and lines)}
## prepare point data sets 

## easiest to run through sets of points grouped by vetted days and recombine.
dgroup = "day10"


observer_column <- "x02_observe"
poc_column <- "x03_pt_type"
mapunit1_column <- "x04_mapunit"
transition_column <- "x05_transit"
mapunit2_column <- "x06_mapunit"
strcst_column <- "x07_struct_"
strcmod_column <- "x08_struct_"
comment_column <- "x09_comment"
edatope_column <- "x10_edatope"
time_column <-"timestamp"

#order_column <- "f11_order"

points <- list.files(file.path(trans_data, "final_contractors",dgroup), pattern = ".gpkg$|.shp$", full.names = TRUE)


all_points <- foreach(x = points, .combine = rbind) %do% {

  #x = points[6]
  
  s1_layers <- st_layers(x)
  pts <- which(s1_layers[["geomtype"]] %in% c("Point","3D Point","3D Measured Point"))

  if(length(pts)>0) { 
    
  print(x)

     points_read <- st_read(x, quiet = TRUE) %>%
     #names(points_read)
     st_transform(3005) %>% 
     st_zm() %>% 
     rename_all(.funs = tolower) 
     
    if("x07_struc_" %in% names(points_read)){
        points_read <- points_read %>% 
          mutate(x07_struct_ = x07_struc_) %>%
          mutate(x08_struct_ = x08_struct)
    }
     
    if("f01_transec" %in% names(points_read)){
        dnames = names(points_read)
        colnames(points_read) <- gsub("f0", "x0", dnames)
        points_read <- points_read %>%
          dplyr::mutate(x10_edatope = f10_edatope)
          
      }
     

     points_read <- points_read %>% 
     mutate(mapunit1 = UQ(rlang::sym(mapunit1_column)),
            mapunit2 = UQ(rlang::sym(mapunit2_column)),
            point_type = UQ(rlang::sym(poc_column)),
            observer = UQ(rlang::sym(observer_column)), 
            transition = UQ(rlang::sym(transition_column)),
            comments = UQ(rlang::sym(comment_column)),
            strcst = UQ(rlang::sym(strcst_column)),
            strcmod = UQ(rlang::sym(strcmod_column)),
            time = UQ(rlang::sym(time_column))) %>%
     st_join(., transect_layout_buf, join = st_intersects) %>%
     rename_all(.funs = tolower) %>%
     rename(transect_id = id)
  
     if("name" %in% names(points_read)){
       points_read <- points_read %>%
         mutate(order = as.numeric(gsub("Placemark ", "", name)))
     }
     # } else {
     #   
     #   points_read <- points_read %>%
     #     mutate(name = seq(1, length(mapunit1),1))
     # }
    points_read <- points_read %>%
     dplyr::select(any_of(c("order", "mapunit1", "mapunit2", "point_type", "transect_id", "observer", "transition", "comments", "strcst", "strcmod", "time" ))) %>%
     group_by(transect_id) %>%
     arrange(as.numeric(order), by_group = TRUE) %>%
     ungroup() 
    
     st_geometry(points_read ) <- "geom"
     print(length(points_read$order))
     points_read
     
  }

} %>% 
  distinct(., .keep_all = TRUE) 

# catergorise data types:
points <- all_points %>%
  mutate(data_type = ifelse(is.na(transect_id), "incidental", "s1"))

# match to the baseunit key using mapunit legend & format observer column

# ## check the site names are matching in key 
# # cross check values with AOI key 
# map.key_sum <- map.key %>% dplyr::select(c(FieldCall, BaseMapUnit)) 
# 
# outdata <- points %>%
#   select(mapunit1, mapunit2)%>%
#   st_drop_geometry() %>%
#   distinct() %>%
#   left_join(map.key_sum, by = c("mapunit1" = "FieldCall")) %>%
#   #dplyr::select(-mapunit1) %>%
#   dplyr::rename(mapunit1_match = BaseMapUnit) %>%
#   left_join(map.key_sum, by = c("mapunit2" = "FieldCall")) %>%
#   #dplyr::select(-mapunit2) %>%
#   dplyr::rename(mapunit2_match = BaseMapUnit) %>%
#   distinct()

points_final <- format_mapunit_names(points, map.key)
points_final <- fill_observer(points_final)
 
# covert to lines 
processed_transects <- make_lines(GPSPoints = points_final, 
                                  Transects = transect_layout_buf, 
                                  method = "pts2lines",  
                                  tBuffer = 20, PROJ = 3005) %>%
  mutate(mapunit1 = (trimws(mapunit1)),
         mapunit2 = (trimws(mapunit2))) %>%
  mutate(mapunit12 = paste0(mapunit1,"_", mapunit2)) %>%
  mutate(mapunit12 = gsub("_NA","", mapunit12)) %>%
  mutate(mapunit12 = gsub("_$","", mapunit12)) %>%
  dplyr::select(-TID, -ID)

st_write(processed_transects,  file.path(output_pnts_dir, paste0(dgroup, "_proc_s1_transects.gpkg")), 
         delete_layer = TRUE)

#processed_transects <- st_read(file.path(output_pnts_dir, "proc_s1_transects.shp"))

st_write(points_final, file.path(output_pnts_dir, paste0(dgroup, "_s1_pts.gpkg")), delete_layer = TRUE)

```


Merge all the processed points together

```{r}

proc_pts <- list.files(output_pnts_dir, pattern = "_s1_pts.gpkg", full.names = TRUE)

s1_points <- foreach(x = proc_pts, .combine = rbind) %do% {
 points_read <- st_read(x, quiet = TRUE) 
}

proc_trans <- list.files(output_pnts_dir, pattern = "_proc_s1_transects.gpkg", full.names = TRUE)

 s1_trans <- foreach(x = proc_trans, .combine = rbind) %do% {
 points_read <- st_read(x, quiet = TRUE) 
}    
     

st_write(s1_points, file.path(output_pnts_dir,"s1_pts.gpkg"), delete_layer = TRUE)

st_write(s1_trans, file.path(output_pnts_dir,"s1_transects.gpkg"), delete_layer = TRUE)


```

# check timing of transects 

```{r}

s1_points

time <- s1_points %>%
  dplyr::select(transect_id, observer, time)%>%
  st_drop_geometry()

min_max <- time %>%
  group_by(transect_id) %>%
  mutate(start = min(time),
         end = max(time))%>%
  select(transect_id, start, end, observer) %>%
  distinct()

min_max < min_max %>%
  mutate(date = )
  






```




